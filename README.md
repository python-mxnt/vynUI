# ğŸŒŒ vynUI

A **self-hosted**, minimalist web interface that connects to your **Ollama API** from any device on your network.

---

> âš ï¸ **Project status:** vynUI is actively in development. Expect frequent updates and experimental features.

If you'd like to follow progress or contribute to planning, check out:
- Miro Board: [Here](https://miro.com/app/board/uXjVJ7OeXkk=/?share_link_id=892158054911)
- Trello Board: [Here](https://trello.com/invite/b/68ebc81134885dadd979a9aa/ATTI2d2c4fe8aa99a17fe9f12413d53fd2c0EA82AA47/vynui)

---

## âœ¨ Key features
- ğŸŒ Connect to your **host Ollama** machine over your local network  
- âš¡ Real-time chat with streaming responses  
- ğŸ’» Lightweight, responsive UI focused on minimalism  
- ğŸ”’ 100% open-source & self-hosted

---

## ğŸ›  Configuration

- The app expects to connect to an Ollama host IP and port â€” update the connection string in the UI connection modal.
- Add any environment variables or config files here if you add server-side logic later.

---

## ğŸ§  How it works (short)
vynUI connects through your local network to a host running Ollama. Messages typed in the UI are forwarded to Ollama, which replies with streaming responses. The UI is deliberately minimal to keep latency and resource usage low.

---

## ğŸ¤ Contributing
Weâ€™d love help. Please read `CONTRIBUTING.md` before opening issues or PRs.

Good first issues:
- Improve documentation or add examples
- Find errors in the code

When opening PRs:
- Keep commits focused and atomic
- Document behavior changes in the PR description
- Add screenshots if the UI is modified

---

## ğŸ“£ Support & Community
If you like this project:
- Star the repo â­  
- PLEASE Share it with devs who run local LLM setups  
- Open issues for bugs or feature requests

Where we plan to share updates:
- Repo releases
- Project boards (Miro / Trello linked above)

---

## ğŸ“œ License
Licensed under the MIT License. See `LICENSE.md`.

Â© 2025 Lunar Productions

---
